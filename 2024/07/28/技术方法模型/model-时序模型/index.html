<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>model-时序模型 | chiblog</title><meta name="author" content="神经蛙"><meta name="copyright" content="神经蛙"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="近期值得关注的4个时序大模型研究 (qq.com)ICML 2024 时间序列（Time Series）和时空数据（Spatial-Temporal）论文总结【抢先版】 (qq.com)https:&#x2F;&#x2F;github.com&#x2F;thuml&#x2F;Time-Series-Library清华大学最新深度时序模型综述+5k star开源代码！ (qq.com)    datamonday&#x2F;Time-S">
<meta property="og:type" content="article">
<meta property="og:title" content="model-时序模型">
<meta property="og:url" content="https://chierhy.github.io/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/model-%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="chiblog">
<meta property="og:description" content="近期值得关注的4个时序大模型研究 (qq.com)ICML 2024 时间序列（Time Series）和时空数据（Spatial-Temporal）论文总结【抢先版】 (qq.com)https:&#x2F;&#x2F;github.com&#x2F;thuml&#x2F;Time-Series-Library清华大学最新深度时序模型综述+5k star开源代码！ (qq.com)    datamonday&#x2F;Time-S">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg">
<meta property="article:published_time" content="2024-07-28T06:17:00.000Z">
<meta property="article:modified_time" content="2024-07-30T05:10:01.000Z">
<meta property="article:author" content="神经蛙">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg"><link rel="shortcut icon" href="https://pic4.zhimg.com/v2-da217cabde0a382120e68118571d60e3_r.jpg"><link rel="canonical" href="https://chierhy.github.io/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/model-%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'model-时序模型',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-30 13:10:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="chiblog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://github.com/chierhy/chierhy.github.io/blob/master/%E9%99%84%E4%BB%B6/1.jpg?raw=true" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">chiblog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">model-时序模型</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-28T06:17:00.000Z" title="发表于 2024-07-28 14:17:00">2024-07-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-30T05:10:01.000Z" title="更新于 2024-07-30 13:10:01">2024-07-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="model-时序模型"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ZscrqfEvb-3zAIlqKnB27A">近期值得关注的4个时序大模型研究 (qq.com)</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Y0rszFAeNplIbK1X-po9Qw">ICML 2024 时间序列（Time Series）和时空数据（Spatial-Temporal）论文总结【抢先版】 (qq.com)</a><br><a target="_blank" rel="noopener" href="https://github.com/thuml/Time-Series-Library">https://github.com/thuml/Time-Series-Library</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/hn9cioL2DRiC3YqQIXyvHQ">清华大学最新深度时序模型综述+5k star开源代码！ (qq.com)</a></p>
</blockquote>
<ul>
<li><input disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://github.com/datamonday/Time-Series-Analysis-Tutorial">datamonday&#x2F;Time-Series-Analysis-Tutorial: 时间序列分析教程 (github.com)</a></li>
</ul>
<h1 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h1><ul>
<li>时频。（单模态。）<br>  - 一致性对时间序列进行自监督对比预训练<a href="%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E6%97%B6%E5%BA%8F-2022-TFC-Self-Supervised%20Contrastive%20Pre-Training%20For%20Time%20Series%20via%20Time-Frequency%20Consistency.md">对比学习-时序-2022-TFC-Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency</a> one to one or one to many——利用 earset 的信息预训练。然后迁移到实验室耳机的数据集、实验室眼镜的数据集、眼镜耳机的其他数据集，说明可跨设备识别表情姿态等。——做一个 all wearble, 因为这篇主要探究 eeg 到别的， HAR 2 GESTURE 的效果只有 0.78，我们可以加上 imu 的 earset 和一些其他 wearble 的数据，形成一个新的可穿戴 imu 时序通用的网络。<br>  - 上面这个是促进时域和频域表征，while pushing them apart from other signals. 因此 Time-series representation learning via Time-Frequency Fusion Contrasting 这篇提出用 kenal pca 融合时频域的增强的数据，融合后的数据和原始数据作为正对。<ul>
<li>结合时频域的对比学习和多通路，训练一个 online 时序数据和我的 imu 时序数据&#x2F;训练我的 video 和我的 imu 数据&#x2F;四个模态视频 landmarks 和 imu 时域频域，交换 pathways，（不愿意上传图像但可以上传 landmarks，）</li>
</ul>
</li>
<li><del>Token. Chronos 通过缩放和量化将时间序列值转换为固定词汇表中的标记</del></li>
</ul>
<h1 id="统一表征"><a href="#统一表征" class="headerlink" title="统一表征"></a>统一表征</h1><p>挑战</p>
<ul>
<li>1）<strong>多领域时间动态：</strong> 统一模型通过在不同数据源上共同训练来学习通用知识，但是时间序列数据在不同领域的时间动态方面存在广泛变异（He 等，2023）。此外，时间序列数据可能具有异构的数据表示，例如变量数量、传感器定义和观测长度。这种时间序列数据的异构性阻碍了为其他领域开发的统一模型的使用（Zhang 等，2023）。因此，必须设计和训练一个统一模型，以捕获通用的时间动态，从而将其转移到新的下游数据集，而不考虑数据表示。</li>
<li>2）<strong>不同的任务规范：</strong> 时间序列数据上的常见任务具有根本不同的目标。例如，预测涉及预测时间序列中的未来值，类似于回归问题，而分类是在整个样本上进行的离散决策过程。此外，不同数据集上的相同任务可能需要不同的规范，例如在长度上变化的生成任务和具有多个类别的识别任务。现有的时间序列模型（Zhou 等，2023；Wu 等，2023）定义了任务特定的模块来处理每个任务，这会影响它们适应不同类型任务的能力。统一模型必须能够适应用户对任务规范的变化。</li>
<li>3）<strong>需要任务特定的时间序列模块：</strong> 统一模型在各种任务之间使用共享权重，增强了它们的泛化能力。然而，以前方法中每个数据集的不同任务特定模块需要对这些模块进行微调。这个过程通常需要精细调整的训练参数以及每个任务的适度数据集大小，阻碍了对新任务的快速适应。这种策略与设计用于同时处理多个任务的统一模型的概念相矛盾。</li>
</ul>
<p><strong>创新点</strong></p>
<ul>
<li>轻量级。</li>
<li>可解释性，信息瓶颈</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul>
<li><p>频谱信息。自适应频谱块</p>
</li>
<li><p>卷积。交互卷积</p>
</li>
<li><p>Token 标记。提示、序列和任务标记。提示微调</p>
</li>
<li><p>拆分成多个 patch。历史信息。</p>
</li>
<li><p>对比学习</p>
</li>
<li><p>表示学习</p>
</li>
<li><p>生成。条件时间序列生成，扩散模型</p>
</li>
<li><p>数学。因果推理，基于拓扑的算法、后代分层拓扑、条件独立准则</p>
</li>
<li><p>第一类模型是基于MLP的建模方法。这类模型很简单，以历史序列作为输入，通过一个全连接网络，映射到输出维度</p>
</li>
<li><p>第二类模型是基于RNN的建模方法，核心是基于RNN的自回归建模能力，对历史规律进行捕捉，并自回归的逐个解码出未来每个时间步的预测结果；</p>
</li>
<li><p>第三类模型是基于CNN的建模方法，包括基础的1D建模，以及在TimesNet中提出的2D建模方法；</p>
</li>
<li><p>第四类模型是基于GNN的建模方法，主要用在多变量时间序列建模中，将各个变量之间的关系，通过图学习的方式刻画出来；</p>
</li>
<li><p>第五类模型是基于Transformer的建模方法（捕捉长期和复杂的多变量关系），也是目前最常见的模型。文中又根据attention的建模维度，进一步分为point-wise、patch-wise、series-wise类型。Point-wise就是最基础的Transformer，每个时间步之间计算attention score（不足以捕捉时态数据的局部语义信息；patch-wise就是PatchTST中的方法，将相邻几个时间步的序列聚合成patch，attention作用到patch之间；series-wise指的是iTransformer这种方法，将一个序列作为整体，attention主要用在变量间关系的计算。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>paper</th>
<th>method</th>
<th align="left">content</th>
<th>优点</th>
<th>link</th>
</tr>
</thead>
<tbody><tr>
<td>2024 UniCL：A Universal Contrastive Learning Framework for Large Time Series Models。</td>
<td>频谱</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024 <strong>UniTS</strong> Building a Unified Time Series Model.</td>
<td>Token</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Chronos: Learning the Language of Time Series</td>
<td>Token</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting</td>
<td></td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>2024 UniCL：A Universal Contrastive Learning Framework for Large Time Series Models。利用频谱信息生成模式保留、多样化和低偏差的时间序列数据. 没有公开代码——利用频谱信息提升算法能力</li>
<li>2024 <strong>UniTS</strong> Building a Unified Time Series Model. 三个 token：提示、序列和任务标记。共享参数处理各种任务，而无需使用任何特定任务的模块。1）<strong>基于提示的通用任务规范：</strong> UNITS 使用基于提示的框架将各种任务转换为统一的标记表示，为所有任务创建通用规范。2）<strong>数据域不可知网络：</strong> UNITS 在序列和变量维度上都使用自注意力来适应各种数据形状。我们引入了一个动态线性算子来模拟任意长度序列中数据点之间的密集关系。因此，UNITS 可以处理具有不同变量和长度的多领域时间序列，而无需修改网络结构。3）<strong>具有完全共享权重的统一模型：</strong> 利用通用任务规范和数据域不可知网络，UNITS 在各任务之间具有共享权重。为了提高 UNITS 的泛化能力，引入了一个统一的掩码重构预训练方案，用于处理统一模型内的生成和识别任务。结合了<strong>多任务、零样本、少样本和提示学习</strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/wjjc1017/article/details/137822681">UniTS：构建统一的时间序列模型 UniTS: Building a Unified Time Series Model-CSDN博客</a> <img src="https://mmbiz.qpic.cn/sz_mmbiz_png/9RtQ04O5eOoTvwdlrcYkNSQ1xHuKy0sibje7vXFP6vGO7Xfgu4hMvC6gWiaS3fDN5tRliaguUw5ZvLXmGnTpicqAEQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1"></li>
<li>Chronos: Learning the Language of Time Series。缩放和量化将时间序列值转换为固定词汇表中的标记，并使用交叉熵损失训练现有的基于 Transformer 的语言模型架构来处理这些标记化的时间序列<img src="https://mmbiz.qpic.cn/sz_mmbiz_png/9RtQ04O5eOoTvwdlrcYkNSQ1xHuKy0sibDB6XugxMbbcSVsnZhwyLAliaLCoqL2ib3LiaG8nxdnpdpYauUEdhIPZOg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1"></li>
<li>Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting 基于解码器 Transformer 架构的通用单变量概率时间序列预测基础模型，它将滞后值作为协变量</li>
</ul>
<h1 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h1><table>
<thead>
<tr>
<th>paper</th>
<th align="left">content</th>
<th>优点</th>
<th>link</th>
</tr>
</thead>
<tbody><tr>
<td>TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS（ICLR 2024）</td>
<td align="left"></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS（ICLR 2024）我们首先使用文本原型（text prototypes）重新编程输入的时间序列，然后将其输入到冻结的 LLM 中，以对齐这两种模态。为了增强 LLM 处理时间序列数据的推理能力，作者提出了 Prompt-as-Prefix（PaP），它丰富了输入上下文，并指导了重新编程输入 patch 的转换。来自 LLM 的转换后的时间序列补丁最终被投影以获得预测<img src="https://mmbiz.qpic.cn/sz_mmbiz_png/9RtQ04O5eOoTvwdlrcYkNSQ1xHuKy0sibXscwkAgWJFXDzlqG2Y99XXnP0eeN9kcg6gUHyPibfkyIlFu73qkUnpA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1"></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://chierhy.github.io">神经蛙</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://chierhy.github.io/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/model-%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/">https://chierhy.github.io/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/model-%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://chierhy.github.io" target="_blank">chiblog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/model-%E5%B0%8F%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><img class="prev-cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">model-小语言模型</div></div></a></div><div class="next-post pull-right"><a href="/2024/07/28/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/task-%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/"><img class="next-cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">task-具身智能</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://github.com/chierhy/chierhy.github.io/blob/master/%E9%99%84%E4%BB%B6/1.jpg?raw=true" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">神经蛙</div><div class="author-info__description">chierhy@163.com</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chierhy"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#idea"><span class="toc-number">1.</span> <span class="toc-text">idea</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E8%A1%A8%E5%BE%81"><span class="toc-number">2.</span> <span class="toc-text">统一表征</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LLM"><span class="toc-number">3.</span> <span class="toc-text">LLM</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E5%B7%A5%E5%85%B7/1-%E6%9C%8D%E5%8A%A1%E5%99%A8-GPU/" title="服务器-GPU"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="服务器-GPU"/></a><div class="content"><a class="title" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E5%B7%A5%E5%85%B7/1-%E6%9C%8D%E5%8A%A1%E5%99%A8-GPU/" title="服务器-GPU">服务器-GPU</a><time datetime="2025-04-12T09:49:28.477Z" title="发表于 2025-04-12 17:49:28">2025-04-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/method-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" title="method-知识蒸馏"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="method-知识蒸馏"/></a><div class="content"><a class="title" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/method-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" title="method-知识蒸馏">method-知识蒸馏</a><time datetime="2025-04-12T09:49:26.684Z" title="发表于 2025-04-12 17:49:26">2025-04-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/7/" title="无题"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2025/04/12/7/" title="无题">无题</a><time datetime="2025-04-12T09:48:44.496Z" title="发表于 2025-04-12 17:48:44">2025-04-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By 神经蛙</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">See you!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>