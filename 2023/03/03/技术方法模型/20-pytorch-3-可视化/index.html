<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>pytorch-3-可视化 | chiblog</title><meta name="author" content="神经蛙"><meta name="copyright" content="神经蛙"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="pytorch-3-可视化">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch-3-可视化">
<meta property="og:url" content="https://chierhy.github.io/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/20-pytorch-3-%E5%8F%AF%E8%A7%86%E5%8C%96/index.html">
<meta property="og:site_name" content="chiblog">
<meta property="og:description" content="pytorch-3-可视化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg">
<meta property="article:published_time" content="2023-03-03T15:33:00.000Z">
<meta property="article:modified_time" content="2023-03-03T15:34:12.000Z">
<meta property="article:author" content="神经蛙">
<meta property="article:tag" content="笔记🎫">
<meta property="article:tag" content="AI👾">
<meta property="article:tag" content="python">
<meta property="article:tag" content="code💻">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg"><link rel="shortcut icon" href="https://pic4.zhimg.com/v2-da217cabde0a382120e68118571d60e3_r.jpg"><link rel="canonical" href="https://chierhy.github.io/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/20-pytorch-3-%E5%8F%AF%E8%A7%86%E5%8C%96/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'pytorch-3-可视化',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-03 23:34:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="chiblog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic4.zhimg.com/v2-da217cabde0a382120e68118571d60e3_r.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">chiblog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">pytorch-3-可视化</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-03T15:33:00.000Z" title="发表于 2023-03-03 23:33:00">2023-03-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-03T15:34:12.000Z" title="更新于 2023-03-03 23:34:12">2023-03-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="pytorch-3-可视化"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Visdom可视化"><a href="#Visdom可视化" class="headerlink" title="Visdom可视化"></a>Visdom可视化</h1><p>官网<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/visdom">https://github.com/facebookresearch/visdom</a><br>visdom由于其功能简单，一般会被定义为服务器端的matplot，也就是说我们可以直接使用python的控制台模式进行开发并在服务器上执行，将一些可视化的数据传送到Visdom服务上，通过Visdom服务进行可视化</p>
<p>使用命令python -m visdom.server 在本地启动服务器，启动后会提示It’s Alive! You can navigate to <a target="_blank" rel="noopener" href="http://localhost:8097/">http://localhost:8097</a> 这就说明服务已经可用，我们打开浏览器，输入<a target="_blank" rel="noopener" href="http://localhost:8097/">http://localhost:8097</a> 即可看到页面。</p>
<p>端口8097是默认的端口可以在启动命令后加 -port参数指定端口，常用的参数还有 –hostname，-base_url等<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36941368/article/details/82288154">https://blog.csdn.net/qq_36941368/article/details/82288154</a><br>新版的不需要了 pip install –upgrade visdom就好</p>
<p>可视化接口<br>Visdom是由Plotly 提供的可视化支持，所以提供一下可视化的接口: - vis.scatter : 2D 或 3D 散点图 - vis.line : 线图 - vis.stem : 茎叶图 - vis.heatmap : 热力图 - vis.bar : 条形图 - vis.histogram: 直方图 - vis.boxplot : 箱型图 - vis.surf : 表面图 - vis.contour : 轮廓图 - vis.quiver : 绘出二维矢量场 - vis.image : 图片 - vis.text : 文本 - vis.mesh : 网格图 - vis.save : 序列化状态</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">env = Visdom() </span><br><span class="line"><span class="keyword">assert</span> env.check_connection() <span class="comment">#测试一下链接，链接错误的话会报错</span></span><br><span class="line"></span><br><span class="line">Y = np.linspace(<span class="number">0</span>, <span class="number">2</span> * math.pi, <span class="number">70</span>)</span><br><span class="line">X = np.column_stack((np.sin(Y), np.cos(Y)))</span><br><span class="line"></span><br><span class="line">env.stem(</span><br><span class="line">        X=X,</span><br><span class="line">        Y=Y,</span><br><span class="line">        opts=<span class="built_in">dict</span>(legend=[<span class="string">&#x27;Sine&#x27;</span>, <span class="string">&#x27;Cosine&#x27;</span>])</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新损失函数</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">x,y=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">env2 = Visdom()</span><br><span class="line">pane1= env2.line(</span><br><span class="line">    X=np.array([x]),</span><br><span class="line">    Y=np.array([y]),</span><br><span class="line">    opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;dynamic data&#x27;</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>) <span class="comment">#每隔一秒钟打印一次数据</span></span><br><span class="line">    x+=i</span><br><span class="line">    y=(y+i)*<span class="number">1.5</span></span><br><span class="line">    <span class="built_in">print</span>(x,y)</span><br><span class="line">    env2.line(</span><br><span class="line">        X=np.array([x]),</span><br><span class="line">        Y=np.array([y]),</span><br><span class="line">        win=pane1,<span class="comment">#win参数确认使用哪一个pane</span></span><br><span class="line">        update=<span class="string">&#x27;append&#x27;</span>) <span class="comment">#我们做的动作是追加，除了追加意外还有其他方式，这里我们不做介绍了</span></span><br></pre></td></tr></table></figure>

<h1 id="Tensorboard可视化"><a href="#Tensorboard可视化" class="headerlink" title="Tensorboard可视化"></a>Tensorboard可视化</h1><p>tensorboard –logdir logs 即可启动，默认的端口是 6006,在浏览器中打开 <a target="_blank" rel="noopener" href="http://localhost:6006/">http://localhost:6006/</a> 即可看到web页面。<br>（这样启动后 网页正常，但加载了图片不显示。解决方法：在Anaconda Prompt中先进入日志存放的目录，再运行TensorBoard，并将日志的地址指向程序日志输出的地址。命令： tensorboard –logdir&#x3D;.&#x2F;logs）(因为下面代码写的是log_dir&#x3D;’.&#x2F;logs’)</p>
<p>IMAGES<br>可视化当前轮训练使用的训练&#x2F;测试图片或者 feature maps</p>
<p>GRAPHS<br>可视化计算图的结构及计算图上的信息，通常用来展示网络的结构</p>
<p>HISTOGRAMS<br>可视化张量的取值分布，记录变量的直方图(统计张量随着迭代轮数的变化情况）</p>
<p>PROJECTOR<br>全称Embedding Projector 高维向量进行可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models,datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里的引用也要修改成torch的引用</span></span><br><span class="line"><span class="comment">#from tensorboardX import SummaryWriter</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">cat_img = Image.<span class="built_in">open</span>(<span class="string">&#x27;./data/cat.jpg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(cat_img.size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1280x853的图，我们先把她变成224x224的图片，因为后面要使用的是vgg16</span></span><br><span class="line">transform_224 = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">224</span>), <span class="comment"># 这里要说明下 Scale 已经过期了，使用Resize</span></span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line">cat_img_224=transform_224(cat_img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示图片</span></span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">&#x27;./logs&#x27;</span>, comment=<span class="string">&#x27;cat image&#x27;</span>) <span class="comment"># 这里的logs要与--logdir的参数一样</span></span><br><span class="line">writer.add_image(<span class="string">&quot;cat&quot;</span>,cat_img_224)</span><br><span class="line">writer.close()<span class="comment"># 执行close立即刷新，否则将每120秒自动刷新</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新损失函数，scalar页面</span></span><br><span class="line">x = torch.FloatTensor([<span class="number">100</span>])</span><br><span class="line">y = torch.FloatTensor([<span class="number">500</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">    x = x * <span class="number">1.2</span></span><br><span class="line">    y = y / <span class="number">1.1</span></span><br><span class="line">    loss = np.random.random()</span><br><span class="line">    <span class="keyword">with</span> SummaryWriter(log_dir=<span class="string">&#x27;./logs&#x27;</span>, comment=<span class="string">&#x27;train&#x27;</span>) <span class="keyword">as</span> writer: <span class="comment">#可以直接使用python的with语法，自动调用close方法</span></span><br><span class="line">        writer.add_histogram(<span class="string">&#x27;his/x&#x27;</span>, x, epoch)</span><br><span class="line">        writer.add_histogram(<span class="string">&#x27;his/y&#x27;</span>, y, epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;data/x&#x27;</span>, x, epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;data/y&#x27;</span>, y, epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;data/loss&#x27;</span>, loss, epoch)</span><br><span class="line">        writer.add_scalars(<span class="string">&#x27;data/data_group&#x27;</span>, &#123;<span class="string">&#x27;x&#x27;</span>: x,</span><br><span class="line">                                                <span class="string">&#x27;y&#x27;</span>: y&#125;, epoch)</span><br></pre></td></tr></table></figure>

<p>使用PROJECTOR对高维向量可视化<br>PROJECTOR的的原理是通过PCA，T-SNE等方法将高维向量投影到三维坐标系（降维度）。Embedding Projector从模型运行过程中保存的checkpoint文件中读取数据，默认使用主成分分析法（PCA）将高维数据投影到3D空间中，也可以通过设置设置选择T-SNE投影方法，这里做一个简单的展示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE=<span class="number">512</span> </span><br><span class="line">EPOCHS=<span class="number">20</span> </span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        datasets.MNIST(<span class="string">&#x27;data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, </span><br><span class="line">                       transform=transforms.Compose([</span><br><span class="line">                           transforms.ToTensor(),</span><br><span class="line">                           transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                       ])),</span><br><span class="line">        batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 1,28x28</span></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">1</span>,<span class="number">10</span>,<span class="number">5</span>) <span class="comment"># 10, 24x24</span></span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">10</span>,<span class="number">20</span>,<span class="number">3</span>) <span class="comment"># 128, 10x10</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">20</span>*<span class="number">10</span>*<span class="number">10</span>,<span class="number">500</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">500</span>,<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        in_size = x.size(<span class="number">0</span>)</span><br><span class="line">        out = self.conv1(x) <span class="comment">#24</span></span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>, <span class="number">2</span>)  <span class="comment">#12</span></span><br><span class="line">        out = self.conv2(out) <span class="comment">#10</span></span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        out = out.view(in_size,-<span class="number">1</span>)</span><br><span class="line">        out = self.fc1(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        out = F.log_softmax(out,dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = ConvNet()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_loader, optimizer, epoch</span>):</span><br><span class="line">    n_iter=<span class="number">0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span>(batch_idx+<span class="number">1</span>)%<span class="number">30</span> == <span class="number">0</span>: </span><br><span class="line">            n_iter=n_iter+<span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line">            <span class="comment">#相对于以前的训练方法 主要增加了以下内容</span></span><br><span class="line">            out = torch.cat((output.data, torch.ones(<span class="built_in">len</span>(output), <span class="number">1</span>)), <span class="number">1</span>) <span class="comment"># 因为是投影到3D的空间，所以我们只需要3个维度</span></span><br><span class="line">            <span class="keyword">with</span> SummaryWriter(log_dir=<span class="string">&#x27;./logs&#x27;</span>, comment=<span class="string">&#x27;mnist&#x27;</span>) <span class="keyword">as</span> writer: </span><br><span class="line">                <span class="comment">#使用add_embedding方法进行可视化展示</span></span><br><span class="line">                writer.add_embedding(</span><br><span class="line">                    out,</span><br><span class="line">                    metadata=target.data,</span><br><span class="line">                    label_img=data.data,</span><br><span class="line">                    global_step=n_iter)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train(model, train_loader, optimizer, 0)</span></span><br><span class="line"><span class="comment"># 打开 http://localhost:6006/#projector 即可看到效果。</span></span><br><span class="line"><span class="comment"># 目前测试投影这部分也是有问题的，根据官网文档的代码进行测试，也显示不出来，正在找原因</span></span><br></pre></td></tr></table></figure>

<p>绘制网络结构<br>使用tensorboard的GRAPHS来实现网络结构的可视化。 由于pytorch使用的是动态图计算，所以我们这里要手动进行一次前向的传播.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vgg16 = models.vgg16(pretrained=<span class="literal">True</span>) <span class="comment"># 这里下载预训练好的模型</span></span><br><span class="line"><span class="built_in">print</span>(vgg16) <span class="comment"># 打印一下这个模型</span></span><br></pre></td></tr></table></figure>

<pre><code>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前向传播前，先要把图片做一些调整</span></span><br><span class="line">transform_2 = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">224</span>), </span><br><span class="line">    transforms.CenterCrop((<span class="number">224</span>,<span class="number">224</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                                std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">vgg16_input=transform_2(cat_img)[np.newaxis]<span class="comment"># 因为pytorch的是分批次进行的，所以我们这里建立一个批次为1的数据集</span></span><br><span class="line">vgg16_input.shape</span><br><span class="line"></span><br><span class="line">out = vgg16(vgg16_input)</span><br><span class="line">_, preds = torch.<span class="built_in">max</span>(out.data, <span class="number">1</span>)</span><br><span class="line">label=preds.numpy()[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(label)</span><br><span class="line"><span class="comment"># 含义是预训练模型中，根据这张图估计的类别。https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/c2c91c8e767d04621020c30ed31192724b863041/imagenet1000_clsid_to_human.txt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> SummaryWriter(log_dir=<span class="string">&#x27;./logs&#x27;</span>, comment=<span class="string">&#x27;vgg161&#x27;</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    writer.add_graph(vgg16, vgg16_input)</span><br></pre></td></tr></table></figure>

<h1 id="可视化cnn"><a href="#可视化cnn" class="headerlink" title="可视化cnn"></a>可视化cnn</h1><p>两类方法，一种是基于Deconvolution, 另一种则是基于反向传播的方法</p>
<p>基于Deconvolution的方法<br>Visualizing and Understanding Convolutional Networks（<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1311.2901">https://arxiv.org/abs/1311.2901</a> ） 主要是将激活函数的特征映射回像素空间，来揭示什么样的输入模式能够产生特定的输出,因为网络是有层级关系的，所以越靠近输出的层级学到的特征越抽象，与实际任务越相关，这里就不多介绍了，这里（<a target="_blank" rel="noopener" href="https://github.com/saketd403/Visualizing-and-Understanding-Convolutional-neural-networks">https://github.com/saketd403/Visualizing-and-Understanding-Convolutional-neural-networks</a> ）有一个使用 keras的实现，有兴趣的可以看看</p>
<p><a target="_blank" rel="noopener" href="https://handbook.pytorch.wiki/chapter4/4.2.3-cnn-visualizing.html#:~:text=%E7%9A%84%E5%8F%AF%E4%BB%A5%E7%9C%8B%E7%9C%8B-,%E5%9F%BA%E4%BA%8EBackpropagation%E7%9A%84%E6%96%B9%E6%B3%95,-%E5%8F%A6%E5%A4%96%E4%B8%80%E7%B1%BB%E7%9A%84">基于Backpropagation的方法</a></p>
<h1 id="fastai"><a href="#fastai" class="headerlink" title="fastai"></a>fastai</h1><p>fastai库是基于他的创始人Jeremy Howard 等人开发的 Deep Learning 课程深度学习的研究，为计算机视觉、文本、表格数据、时间序列、协同过滤等常见深度学习应用提供单一、一致界面的深度学习库，可以做到开箱即用。这意味着，如果你已经学会用fastai创建实用的计算机视觉（CV）模型，那你就可以用同样的方法创建自然语言处理（NLP）模型，或是其他模型。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/fastai">https://github.com/fastai</a></p>
<p><a target="_blank" rel="noopener" href="https://handbook.pytorch.wiki/chapter4/4.3-fastai.html#:~:text=4.3.2-,fastai%E5%AE%9E%E8%B7%B5,-MNIST">fastai实践</a></p>
<h1 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h1><p>三个方式</p>
<ol>
<li><p>torch.nn.DataParalle<br>一般情况下我们都会使用一台主机带多个显卡，这样是一个最节省预算的方案，在Pytorch中为我们提供了一个非常简单的方法来支持但主机多GPU，那就torch.nn.DataParalle 我们只要将我们自己的模型作为参数，直接传入即可，剩下的事情Pytorch都为我们做了</p>
<p>我们只需要增大我们训练的batch_size(一般计算为N倍，N为显卡数量)，其他代码不需要任何改动。 虽然代码不需要做更改，但是batch size太大了训练收敛会很慢，所以还要把学习率调大一点。大学率也会使得模型的训练在早期的阶段变得十分不稳定，所以这里需要一个学习率的热身（warm up） 来稳定梯度的下降，然后在逐步的提高学习率。</p>
<p>这种热身只有在超级大的批次下才需要进行，一般我们这种一机4卡或者说在batch size 小于 5000（个人测试）基本上是不需要的。例如最近富士通使用2048个GPU,74秒训练完成resnet50的实验中使用的batch size 为 81920 arivx这种超大的size才需要。</p>
<p>DataParallel的并行处理机制是，首先将模型加载到主 GPU 上(默认的第一个GPU，GPU0为主GPU)，然后再将模型复制到各个指定的从 GPU 中，然后将输入数据按 batch 维度进行划分，具体来说就是每个 GPU 分配到的数据 batch 数量是总输入数据的 batch 除以指定 GPU 个数。每个 GPU 将针对各自的输入数据独立进行 forward 计算，最后将各个 GPU 的 loss 进行求和，再用反向传播更新单个 GPU 上的模型参数，再将更新后的模型参数复制到剩余指定的 GPU 中，这样就完成了一次迭代计算。</p>
<p>DataParallel其实也是一个nn.Model所以我们可以保存权重的方法和一般的nn.Model没有区别，只不过如果你想使用单卡或者cpu作为推理的时候需要从里面读出原始的model</p>
<p>DataParallel会将定义的网络模型参数默认放在GPU 0上，所以dataparallel实质是可以看做把训练参数从GPU拷贝到其他的GPU同时训练，这样会导致内存和GPU使用率出现很严重的负载不均衡现象，即GPU 0的使用内存和使用率会大大超出其他显卡的使用内存，因为在这里GPU0作为master来进行梯度的汇总和模型的更新，再将计算任务下发给其他GPU，所以他的内存和使用率会比其他的高。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用内置的一个模型，我们这里以resnet50为例</span></span><br><span class="line">model = torchvision.models.resnet50()</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型使用多GPU</span></span><br><span class="line">mdp = torch.nn.DataParallel(model)</span><br><span class="line">mdp</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取到原始的model</span></span><br><span class="line">m=mdp.module</span><br><span class="line">m</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>torch.distributed</p>
<p> 构建更为同步的分布式运算。使用torch.distributed不仅可以支持单机还可以支持多个主机，多个GPU进行计算。<br> torch.distributed相对于torch.nn.DataParalle 是一个底层的API，所以我们要修改我们的代码，使其能够独立的在机器（节点）中运行。我们想要完全实现分布式，并且在每个结点的每个GPU上独立运行进程，这一共需要N个进程。N是我们的GPU总数，这里我们以4来计算。<br> 首先 初始化分布式后端，封装模型以及准备数据，这些数据用于在独立的数据子集中训练进程。<br> <a target="_blank" rel="noopener" href="https://handbook.pytorch.wiki/chapter4/4.5-multiply-gpu-parallel-training.html#:~:text=4.5.2-,torch.distributed,-torch.distributed%E7%9B%B8">代码</a></p>
</li>
<li><p>torch.utils.checkpoint<br> 在我们训练时，可能会遇到（目前我还没遇到）训练集的单个样本比内存还要大根本载入不了，那如何来训练呢？</p>
<p> pytorch为我们提供了梯度检查点（gradient-checkpointing）节省计算资源，梯度检查点会将我们连续计算的元正向和元反向传播切分成片段。但由于需要增加额外的计算以减少内存需求，该方法效率会有一些下降，但是它在某些示例中有较为明显的优势，比如在长序列上训练RNN模型，这个由于复现难度较大 就不介绍了，官方文档在<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/checkpoint.html">这里</a> 遇到这种情况的朋友可以查看下官方的解决方案。</p>
</li>
</ol>
<p>在PyTorch中使用DistributedDataParallel进行多GPU分布式模型训练<br><a target="_blank" rel="noopener" href="https://handbook.pytorch.wiki/chapter4/distributeddataparallel/readme.html">https://handbook.pytorch.wiki/chapter4/distributeddataparallel/readme.html</a></p>
<h1 id="数据竞赛平台"><a href="#数据竞赛平台" class="headerlink" title="数据竞赛平台"></a>数据竞赛平台</h1><p>kaggle</p>
<p><a target="_blank" rel="noopener" href="https://www.drivendata.org/">DrivenData</a></p>
<p><a target="_blank" rel="noopener" href="https://www.crowdanalytix.com/community">CrowdANALYTIX</a></p>
<p><a target="_blank" rel="noopener" href="https://www.innocentive.com/our-solvers/">InnoCentive</a></p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/top-competitive-data-science-platforms-other-than-kaggle-2995e9dad93c">TundIT</a></p>
<p><a target="_blank" rel="noopener" href="https://competitions.codalab.org/">Codalab</a></p>
<p><a target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/">Analytics Vidhya</a></p>
<p><a target="_blank" rel="noopener" href="https://www.crowdai.org/challenges">CrowdAI</a></p>
<p><a target="_blank" rel="noopener" href="https://numer.ai/rounds">Numerai</a></p>
<p><a target="_blank" rel="noopener" href="https://www.datasciencechallenge.org/">Data Science Challenge</a></p>
<p><a target="_blank" rel="noopener" href="https://www.kdd.org/kdd2019/kdd-cup">KDD Cup</a></p>
<p><a target="_blank" rel="noopener" href="https://tianchi.aliyun.com/competition/gameList/activeList">天池</a></p>
<p><a target="_blank" rel="noopener" href="https://algo.qq.com/">腾讯广告算法大赛</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://chierhy.github.io">神经蛙</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://chierhy.github.io/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/20-pytorch-3-%E5%8F%AF%E8%A7%86%E5%8C%96/">https://chierhy.github.io/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/20-pytorch-3-%E5%8F%AF%E8%A7%86%E5%8C%96/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://chierhy.github.io" target="_blank">chiblog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0%F0%9F%8E%AB/">笔记🎫</a><a class="post-meta__tags" href="/tags/AI%F0%9F%91%BE/">AI👾</a><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/code%F0%9F%92%BB/">code💻</a></div><div class="post_share"><div class="social-share" data-image="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/18/%E6%8A%80%E6%9C%AF%E5%B7%A5%E5%85%B7/6-%E7%88%AC%E8%99%ABb%E7%AB%99%E9%9F%B3%E9%A2%91%E8%A7%86%E9%A2%91/"><img class="prev-cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">爬虫b站音频视频</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/19-pytorch-2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><img class="next-cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">pytorch-2-深度学习</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/25/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/18-Pytorch-1-%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/" title="Pytorch-1-入门笔记"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-25</div><div class="title">Pytorch-1-入门笔记</div></div></a></div><div><a href="/2023/03/03/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/19-pytorch-2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="pytorch-2-深度学习"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-03</div><div class="title">pytorch-2-深度学习</div></div></a></div><div><a href="/2022/11/15/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/2-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-Pytorch%20CNN%20model/" title="学习记录-Pytorch CNN model"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-15</div><div class="title">学习记录-Pytorch CNN model</div></div></a></div><div><a href="/2023/11/09/%E5%AD%A6%E7%A7%91-%E7%AB%9E%E8%B5%9B-%E9%A1%B9%E7%9B%AE/%E8%AF%BE%E7%A8%8B-%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="课程-模式识别与机器学习"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-09</div><div class="title">课程-模式识别与机器学习</div></div></a></div><div><a href="/2023/09/12/%E7%94%9F%E6%B4%BB/%E6%88%91%E8%AF%BB=%E8%99%9A%E6%8B%9F%E6%98%BE%E7%A4%BA%EF%BC%9A%E5%BC%95%E9%A2%86%E6%9C%AA%E6%9D%A5%E7%9A%84%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E9%9D%A9%E5%91%BD/" title="我读&#x3D;虚拟显示：引领未来的人机交互革命"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-12</div><div class="title">我读&#x3D;虚拟显示：引领未来的人机交互革命</div></div></a></div><div><a href="/2023/02/05/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/16-Quantum%20Machine%20Learning/" title="Quantum Machine Learning"><img class="cover" src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-05</div><div class="title">Quantum Machine Learning</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://pic4.zhimg.com/v2-da217cabde0a382120e68118571d60e3_r.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">神经蛙</div><div class="author-info__description">chierhy@163.com</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">120</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chierhy"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Visdom%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">1.</span> <span class="toc-text">Visdom可视化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tensorboard%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">Tensorboard可视化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96cnn"><span class="toc-number">3.</span> <span class="toc-text">可视化cnn</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#fastai"><span class="toc-number">4.</span> <span class="toc-text">fastai</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9AGPU%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">多GPU训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B%E5%B9%B3%E5%8F%B0"><span class="toc-number">6.</span> <span class="toc-text">数据竞赛平台</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E5%B7%A5%E5%85%B7/1-%E6%9C%8D%E5%8A%A1%E5%99%A8-GPU/" title="服务器-GPU"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="服务器-GPU"/></a><div class="content"><a class="title" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E5%B7%A5%E5%85%B7/1-%E6%9C%8D%E5%8A%A1%E5%99%A8-GPU/" title="服务器-GPU">服务器-GPU</a><time datetime="2025-04-12T09:49:28.477Z" title="发表于 2025-04-12 17:49:28">2025-04-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/method-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" title="method-知识蒸馏"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="method-知识蒸馏"/></a><div class="content"><a class="title" href="/2025/04/12/%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B/method-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" title="method-知识蒸馏">method-知识蒸馏</a><time datetime="2025-04-12T09:49:26.684Z" title="发表于 2025-04-12 17:49:26">2025-04-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/12/7/" title="无题"><img src="https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2025/04/12/7/" title="无题">无题</a><time datetime="2025-04-12T09:48:44.496Z" title="发表于 2025-04-12 17:48:44">2025-04-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://pic2.zhimg.com/v2-d29a9ed9425ed9aae1d78cd5e9f3a9f1_r.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By 神经蛙</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">See you!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>